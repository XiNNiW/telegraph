# About 
This project is a virtual instrument that explores a unique sounding, non-linear filter design that I found it Risto Holopanien's [paper](https://ristoid.net/research/NL-filters.pdf) on the subject. (See section 4 for the filter architecture.) 

Working on telegraph has been an opportunity for me to teach myself about some fundamentals of DSP programming in `c++`. As a result, I have chosen to implement all important DSP in my own [library](https://github.com/XiNNiW/algae) as opposed to using JUCE or FAUST to implement the DSP. It has also allowed me to explore the advantages and limitations of organizing code into [pure functional core and imperitive shell](https://www.destroyallsoftware.com/screencasts/catalog/functional-core-imperative-shell).

## Project Goals

1. Design an instrument with a unique sound that I would want to use and that others feel comfortable using.
1. Learn dsp audio programming in `c++`.
1. Investigate the practicality of using functional programming inspired techniques for dsp in an imperitive language.

### Instrument Design
While working as a High-Tech Anthropologist® at Menlo Innovations I became curious how these user centered design practices might be applied to musical instrument design. It was not immidiately clear to me, however, how these techniques would be best applied to the domain of instrument design. High-tech Anthropology is laser focused preventing pain in the end user experience and seeks to strike a balance between end-user needs and the needs of the business. While this concept certainly makes sense for commercial audio software development, how would it best be used for a project that does not have commercial intent? How would the artistic needs of the instrument designer be balanced with the artists that may wish to use it? How would I fare attempting these techniques alone, without the distance afforded by being a consultant paid to provide an outside perspective?

### Learning DSP programming
In recent years I have become curious about creating digital synthesizers in low power hardware. While I have experience in developing sound manipulating programs in higher-level syntheisis and sound design languages (Max MSP, Supercollider, Pure Data), I never felt like I really understood how it all worked at the lowest level. This project seemed like a good excuse to learn the lower level functions of filters and oscillators by building everything "from scratch" in `c++`. I have saved my learning in the form of my own humble DSP library [Algae](https://github.com/XiNNiW/algae).

### Functional Design
I have found Functional Design principals extremely useful in writing stable and maintainable code. In particular, I have found the concpet of referential transparency extremely useful in writing testable code whose function is independant of other parts of a given system. However, functional programming techniques are often difficult to use outside of specialized functional programming languages. How might functional programming be used for audio dsp in a language that was not specialized for it? What features of FP remain available and is it worth contorting the architecture to maintain referential transparency? Mutative operations in DSP code are often a source of efficiency as they prevent processor cycles from being wasted on copying data from one place to another. Would it be possible to write efficient functional DSP code in an imperitive language?
DSP code in `c++` seemed like a good place to learn more. DSP code is commonly written imperitivley; mutating sample values over various operations. However, it is very natural to describe the operations in terms of pure functions. (For a pure functional DSP language, see [FAUST](https://faust.grame.fr/))
You might look at the source code, or even the language choice (`c++`) and think "What do you mean functional programming?" Even with the additions of some functional language features in recent years, `c++` is not ideal for functional programming and does not implement the features neccessary to effectivly utilize the patterns of abstraction most functional languages typically use to organize code. (ex. heavy use of recursion, first class functions, partial function application, optimized tail recursion, monads, ect...) This being said, I believe that most valuable practical aspect of functional design is still available; referentially transparent functions. Most dsp functions in algae have the following form:
```
const inline std::tuple<state_t, sample_t> process(const state_t& state, const sample_t& input){
    ...[DSP CODE HERE]...
    return std::pair(newState, ouput);
}
```

In the code above, `state_t` is a datatype describing the state that needs to be remembered between computations of a particular dsp algorithm. For example, if implementing a filter, we could define an `fir_t` that hold the previous input samples and their coefficients. `sample_t` would be a templated stand in for `float` or whatever datatype represents a sample of audio. The function above is incapable of mutating its input arguments as they either designated `const`. It also avoids the overhead of copying them as they are passed by reference. While the code inside `proceess` my look imperitive, the `process` method is completely referentially transparent, making its behavior perfectly predictable given a set of input arguments. Its operation is naturally isolated from other dsp processes and can be tested in isolation.
Additional data copies on return may also be mitigated by c++11's move semantics.

## Project History and Design Process
### Project Inception
The initial idea for this project started at a [North Coast Modular Collective](http://www.northcoastmodularcollective.com/) meetup at the Ann Arbor District Library in 2018. Joe Bauer and I were talking to local artist/polymath [Arthur Durkee](http://arthurdurkeemusic.com/) about his use of chaos in his modular setup. In passing, he mentioned fractal filters. In researching this topic, Joe and I stumbled on Risto Holopainen's [paper](https://ristoid.net/research/NL-filters.pdf) on non-linear chaotic filters. 
### Early Prototypes
I began to prototype various designs in Pure Data in order to get a sense of the sound. Unable to easily approximate the design for the 2nd filter presented in section 4, I learned enough FAUST to create several Pure Data externals and Supercollider UGens. At some point, Joe and I got a [FAUST prototype](https://github.com/NorthCoastModularCollective/TelegraphBandpass) to run on a Teensy 3.6 chip. In all cases the results were interesting enough to warrent more tinkering. In order to play with these filters in a musical context, I created several Supercollider synths compatable with the [Tidalcycles](https://tidalcycles.org/) livecoding enviroment and began to write [music](https://github.com/XiNNiW/tidalcyclesjournal) with them. This process was useful to prototypeing more complete instruments and finding some sweet spots for parameters. After creating some pieces that used this sound I wanted to create an instrument that would be easier to use in contexts outside tidal and algorave. I decided that a cross platform VST3 would be a good choice as this would allow me to share this instrument with musicians who work in different DAW and operating systems than I do.
### VST3 design and design assessments
I wanted to use design principles that I learned as a High-Tech Anthropologist® at [Menlo Innovations](https://menloinnovations.com/). In [Menlo's High-Tech Anthropology®](https://menloinnovations.com/services/high-tech-anthropology) process, the user discovery phase of the project is followed by a series of design assesments where paper prototypes of the software are explored by end users. Feedback from these sessions is used to iteratively refine the design, yeilding a tool that prioritizes the end user needs and can be used intuitively without training or instruction.
Given the importance of audio feedback to the domain, and limited resources (a team of one individual), I opted to create a functional prototype of the instrument and assess based on that prototype. In the first round of design assessments I chose to prioritize testing contrasting parameter names and layouts. 
I implemented a version of one of the Tidalcycles prototypes in `c++` and created a vst plugin that exposed the synth parameters without any custom UI. By default, most DAWs show this kind of plugin to users as a list of named parameter knobs. With this bare-bones "design", I conducted design assessments with 3 potential end users to collect feedback on basic sound editing workflow and parameter language. I then refined the language and the parameters and conducted a 2nd round of assessments with 2 more potential end users. The results of these sessions helped me choose a small set of useful parameters, resolve problems posed by sensitive interdependant parameters, and name the parameters sensibly. These sessions also generated a large number of potential feature improvements that could be prioritized for a version 2.
### Minimal Viable Product
Using what I learned from the design assessment process, I refined the core synthesizer design and created a simple UI in JUCE. During this phase I also made basic optimizations including using look-up tables for trig functions, and refactoring the synthesizer code to allow for auto-vectorization over audio block computations. Auto-vectorization and block processing enabled the synth voice to run with high unison without monopolizing the available cpu power.
As with the design phase, some trade-off decisions were made to enable my small team of one to quickly implement a MVP version. Given that I did not intend to market or support this MVP version I opted to not test drive the implementation of the UI and treated this layer as throwaway code. Some basic tests were created for the core synthesizer layer to ensure that each function would not produce `nan`, `inf` or other problematic numerical values. Additionally, I opted to create more rigorous tests as a debugging technique when issues were encountered. 

## Results
I am very pleased with the sound of this instrument. The most common comment I've gotten when assessing it with other musicians is "Is there reverb on it?" (there isn't). There is somthing strange and beautiful about this distorted bandpass that, at least with certain settings, creates a smearing diffusion-like effect. The VST3 plugin was able to be distributed to friends and used in musical applications.

## Reflections and Future Work
### Future Instruments
During design assements, a common question I encountered was: "Is there a version of this that just has the filter? I want to run my own sounds through it." It would be fairly simple to devise an FX version of this plugin that replaces the exciter section with external audio input and reduces the dependancy on keytracking midi notes to set the filter frequencies. I would also love to create a eurorack version of this instrument both because I think it would work very naturally in that environment and because I wish to test the flexibility and performance of the DSP code in an embedded environment. In particular, I would like to learn about the effects of using fixed-point arithmetic on the sound and behavior of this filter.
### Potential Applications in Reverb
Another common question I encountered was: "Is there a reverb on this thing?" This leads me to be curious about using this filter design as a kind of combo resonator and diffusion source in a reverb design. The noisy smearing effect of this filer given certain conditions may be very effective in creating a cheap to compute reverb.
### Further Optimizations
Auto-vectorization enabled a significant performance boost. The performace could be increased further by directly utilizing SIMD (Single Instruction Mulitple Data) instructions through the use of intrisics. This would pose an interesting conflict between performance on desktop environments and my desire to keep the DSP code as processor agnostic as possible. It may be possible to create templated versions of the AudioBlock that utilize intrinsics without polluting the core synthesizer logic with processor/platform specific code.
### Core/Shell Seperation
Overall the seperation of Core dsp implementation from Shell UI has left me with a good deal of flexiblility. The UI layer could be entirely thrown away and most every meaningful aspect of the instrument would be entirely intact. This flexibility could (and should) be tested by creating an LV2 plugin based on the core telegraph code. Additionally, the pure functional nature of the DSP code allowed the behavior of each dsp function to be easily seperated. When a problem arose, its source was easily identified.
### Core/Shell Seperation - unit testing
I am confident that the decision to forgo traditional test driving both saved and wasted time. On the one hand, It allowed rapid iterations of the code to be used in the design assesment process. However, lack of comprehensive unit tests, and implementation first thinking very likely contributed to preventable debugging time and unknown bugs. Choosing not to test drive also limited my ability to evaluate strengths and weaknesses of the Core/Shell seperation pattern in this domain as any professional application of this technique would, in my opinion, require a test-driven approach. From the tests that I did write, I believe that the core synthesizer code as written is testable. However, ["London stye"](https://medium.com/@adrianbooth/test-driven-development-wars-detroit-vs-london-classicist-vs-mockist-9956c78ae95f) testing utilizing mock functions and objects would very likely be impossible. At the moment, at least for DSP code, I believe this is a feature and not a bug. Future unit tests would need to make mathematical assertions about the spectra of the output, its loudness over time, the sensitivity to parameter changes and other aspects that are directly meaningful to the sound. The creation of these tests would require an initial investment in testing utilities that could measure these properties. However, I believe that the resulting tests would be much more meaningful and useful descriptors of each unit than tests that make assertions about the precise implementation. The JUCE/UI layer would require re-implementation with "london-style" mocking and unit testing techniques.

